{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE: Maximum Likelihood Estimation (Estimación de máxima verosimilitud)\n",
    "\n",
    "Es una técnica que nos permite _estimar_ densidades de probabilidad de un conjunto de datos.\n",
    "\n",
    "Su objetivo es buscar la forma más óptima de ajustar una distribución a los datos.\n",
    "\n",
    "Puntos clave:\n",
    "\n",
    "- Escoger una distribución: Teniendo solo una muestra de datos.\n",
    "\n",
    "- Escoger los parámetros de la distribución: Que ajusten mejor la distribución a los datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un problema fundamental del MLE es que no tenemos la población total de los datos, sino solamente una muestra de ellos.\n",
    "\n",
    "\n",
    "MLE es un problema de optimización."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal con MLE\n",
    "\n",
    "$$ y = \\underbrace{m}_{\\text{pendiente}} x + \\overbrace{b}^{\\text{intercepto}} = \\underbrace{b_0}_{\\text{weight}} x + \\overbrace{b_1}^{\\text{bias}} $$\n",
    "<br>\n",
    "\n",
    "La ecuación de la recta de toda la vida se utiliza en Machine Learning, algunos parámetros tendrán un nombre distinto, pero es la misma ecuación.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "$$P(y|x) \\rightarrow max\\sum_i{log P(y_i | x_i; \\overbrace{h}^{\\text{modelo}})} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En regresión lineal se utiliza un método conocido como 'mínimos cuadrados'.\n",
    "Este método busca minimizar la suma de las diferencias entre el valor de $y (y_i)$  y el valor teórico de $y (mx_i + b)$, elevando el resultado al cuadrado para así eliminar cualquier valor negativo. Podemos escribir la formula así:\n",
    "\n",
    "### Mínimos cuadrados: $$ \\boxed{\\min \\sum_{i}{(y_i -mx_i + b)}^2} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estimación de máxima verosimilitud es equivalente al método de los mínimos cuadrados que vemos arriba."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ \\max{ \\displaystyle\\sum_{i} {\\ln P (y_i, x_i, h)}} = \\max{ \\displaystyle\\sum_{i} {\\ln \\bigg(   \\frac{1}{\\sigma\\sqrt{2\\pi}} \\LARGE{e}^{-\\frac{1}{2}(\\frac{y_i - (mx_i + b) {\\sigma}  })} \\bigg) } }$\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
